{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example) Training Vectorizers with SQuAD corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a `SquadGuru` object who is an NLP expert. Let him `gather` the complex squad json dataset organized to make it usable in an NLP task.\n",
    "\n",
    "   - Constructor Signature\n",
    "\n",
    "     ```python\n",
    "     SquadGuru(parser: SquadParser, #parser which implement SquadParser\n",
    "               tokenizer=None, #tokenizer which implement .tokenize(text: str)\n",
    "               tags=SQUAD_TAGS, #iterable of str\n",
    "               versions=SQUAD_VERSIONS #iterable of float\n",
    "     )\n",
    "     ```\n",
    "\n",
    "   - Inject a `parser`, which the guru will use to extract X and Y data from the original suqad dataset.\n",
    "   - Inject a `tokenizer` that will be used to create tokenized X and Y.\n",
    "   - Inject an iterable of `tags` that describes the tags of the dataset to load.\n",
    "   - Inject an iterable of `versions` that describes the versions of the dataset to load. Version's datatype is `float`.\n",
    "\n",
    "\n",
    "   Here we're gonna use `CorpusParser`. In order to create an instance of it, use static factory method pattern like: `SquadParser.from_nlp_task('CORPUS')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_squad import SquadGuru\n",
    "from prep_squad import SquadParser\n",
    "\n",
    "squad_parser = SquadParser.from_nlp_task('CORPUS')\n",
    "guru = SquadGuru(squad_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use `squadGuru.gather()` to let the guru remember extracted X and Y.\n",
    "\n",
    "   - Method Signature\n",
    "\n",
    "     ```python\n",
    "     squadGuru.gather(only_first_answer=False, \n",
    "                      verbose=False)\n",
    "```\n",
    "     \n",
    "     - Set `only_first_answer` to extract the first answer in each of question-answers sets.\n",
    "     - Set `verbose` to print some logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD-v1.1 train dataset has been parsed.\n",
      "SQuAD-v2.0 train dataset has been parsed.\n",
      "SQuAD-v1.1 dev dataset has been parsed.\n",
      "SQuAD-v2.0 dev dataset has been parsed.\n"
     ]
    }
   ],
   "source": [
    "guru.gather(only_first_answer=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the SQuAD Corpus\n",
    "- Because ground-truth labels are not needed, just use `guru.X` to get the corpus from SQuAD datasets.\n",
    "- It is a list that contains the texts from the SQuAD's passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41199\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "corpus = guru.X\n",
    "\n",
    "print(len(corpus))\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tfidf Vectorizer\n",
    "- Let us train `sklearn.feature_extraction.text.TfIdfVectorizer` using the SQuAD corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorizer.set_params(ngram_range=(1, 3))\n",
    "vectorizer = vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"\"\"The iPod has also been credited with accelerating shifts within the music industry. The iPod's popularization of digital music storage allows users to abandon listening to entire albums and instead be able to choose specific singles which hastened the end of the Album Era in popular music.\n",
    "\"\"\"\n",
    "\n",
    "doc2 = \"\"\"Soviet generals with extensive combat experience from the Second World War were sent to North Korea as the Soviet Advisory Group. These generals completed the plans for the attack by May.\n",
    "\"\"\"\n",
    "\n",
    "vectors = vectorizer.transform([doc1, doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.inverse_transform(vectors)\n",
    "tfidfs = []\n",
    "for doc_id, vector in enumerate(vectors):\n",
    "    tfidf = {}\n",
    "    be = vector.indptr.tolist()\n",
    "    for feature_id in range(be[0], be[1]):\n",
    "        tfidf[words[doc_id][feature_id]] = vector.data[feature_id]\n",
    "    tfidfs.append(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tfidf = sorted(tfidf.items(), key=lambda d: d[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('generals', 0.22023447373849717),\n",
       " ('world war sent', 0.16716567545813155),\n",
       " ('war sent north', 0.16716567545813155),\n",
       " ('soviet generals extensive', 0.16716567545813155),\n",
       " ('soviet generals', 0.16716567545813155),\n",
       " ('soviet advisory group', 0.16716567545813155),\n",
       " ('soviet advisory', 0.16716567545813155),\n",
       " ('sent north korea', 0.16716567545813155),\n",
       " ('plans attack', 0.16716567545813155),\n",
       " ('north korea soviet', 0.16716567545813155),\n",
       " ('korea soviet advisory', 0.16716567545813155),\n",
       " ('group generals completed', 0.16716567545813155),\n",
       " ('group generals', 0.16716567545813155),\n",
       " ('generals extensive combat', 0.16716567545813155),\n",
       " ('generals extensive', 0.16716567545813155),\n",
       " ('generals completed plans', 0.16716567545813155),\n",
       " ('generals completed', 0.16716567545813155),\n",
       " ('extensive combat experience', 0.16716567545813155),\n",
       " ('extensive combat', 0.16716567545813155),\n",
       " ('experience second world', 0.16716567545813155),\n",
       " ('experience second', 0.16716567545813155),\n",
       " ('completed plans attack', 0.16716567545813155),\n",
       " ('completed plans', 0.16716567545813155),\n",
       " ('combat experience second', 0.16716567545813155),\n",
       " ('advisory group generals', 0.16716567545813155),\n",
       " ('war sent', 0.1590543620958929),\n",
       " ('korea soviet', 0.1590543620958929),\n",
       " ('soviet', 0.15515758169292004),\n",
       " ('combat experience', 0.15371157656996906),\n",
       " ('advisory group', 0.15371157656996906),\n",
       " ('sent north', 0.14972099742632744),\n",
       " ('advisory', 0.12013526822455475),\n",
       " ('north korea', 0.11563580459888964),\n",
       " ('second world war', 0.1071979228062573),\n",
       " ('second world', 0.10625667957995832),\n",
       " ('combat', 0.09791852192776507),\n",
       " ('korea', 0.09420054742344393),\n",
       " ('plans', 0.09105793521338028),\n",
       " ('extensive', 0.08896505169921962),\n",
       " ('completed', 0.08732283781010422),\n",
       " ('experience', 0.08482565393824597),\n",
       " ('attack', 0.08251392940460753),\n",
       " ('sent', 0.08161770741020083),\n",
       " ('world war', 0.07647325761145535),\n",
       " ('group', 0.06632103928608761),\n",
       " ('second', 0.059972273081156414),\n",
       " ('north', 0.058918087365067116),\n",
       " ('war', 0.0556649038839122),\n",
       " ('world', 0.05032616598233868)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('squad_tfidf_vectorizer.skl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
